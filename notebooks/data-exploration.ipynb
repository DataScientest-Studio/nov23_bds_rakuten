{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T35wEM3_-Ub3"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fJgBvap-BqP"
      },
      "source": [
        "## Objectif du projet\n",
        "\n",
        "L'objectif du projet est de cataloguer des produits selon un code type désignant le type du produit. La prédiction du type doit se faire à partir de données textuelles (désignation et description du produit) ainsi que de données visuelles (image du produit)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC1bI8Fl-ExM"
      },
      "source": [
        "## Contexte\n",
        "\n",
        "Ce projet s’inscrit dans le challenge Rakuten France Multimodal Product Data Classification, les données et leur description sont disponibles à l’adresse : https://challengedata.ens.fr/challenges/35\n",
        "\n",
        "* Les données textuelles : ~60 mb\n",
        "* Données images : ~2.2 gb\n",
        "* 99k données avec plus de 1000 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roovlZv4-IB6"
      },
      "source": [
        "## Fichiers fournis\n",
        "\n",
        "* X_train.csv: Contient les variables explicatives destinées à l’entraînement des modèles.\n",
        "  * index (nb entier): Index du produit.\n",
        "  * designation (object: string): Designation courte du produit\n",
        "  * description (object: string, optionnel): Description du produit. Ce champ est optionnel. Tous les produits n'ont pas de description\n",
        "  * productid (int64): L'id du produit\n",
        "  * imageid (int64): L'id de l'image du produit\n",
        "\n",
        "* images.zip: Une fois extrait, un dossier contenant les images des produits. La nomenclature utilisée permet de faire la jonction avec les produits. Chaque fichier d'image se présente sous la forme: `image_<imageid>_product_<productid>.jpg`. Les images sont répartis en deux sous-dossiers:\n",
        "  * image_train: Les images correspondants à X_train.csv\n",
        "  * image_test: Les images correspondants à X_test.csv\n",
        "\n",
        "* Y_train.csv: Contient la variable cible à prédire. A savoir le type du produit.\n",
        "  * index (nb entier): Index du produit. Permet de faire la jonction avec X_train.csv\n",
        "  * prdtypecode (nb entier): Le type du produit\n",
        "\n",
        "* X_test.csv: Contient les variables explicatives destinées à l'évaluation des modèles. Sa structure est identique à celle de X_train.csv. Ce fichier étant fourni dans le contexte du challenge Rakuten, nous n'avons pas obtenu de fichier Y_test.csv qui nous permettrait de comparer nos performances à celles des participants au challenge. Il est probable qu'on doive se contenter de scinder le dataset d’entraînement en une partie entraînement et une partie test.\n",
        "\n",
        "> **Note**: Nous avons légèrement modifié les entêtes des fichiers d'origine en y ajoutant le titre de colonne index pour la première colonne\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kymzCMSe-LXH"
      },
      "source": [
        "## Métrique utilisée pour l'évaluation de la performance\n",
        "\n",
        "La métrique **weighted-F1 score** a été choisie dans le cadre du challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XARbrUHP-Oxq"
      },
      "source": [
        "## Intérêts du projet\n",
        "\n",
        "Étant réalisé dans le cadre de la formation datascientest, ça va aussi être l'opportunité pour nous de découvrir et mettre en applications des techniques de machine learning avancées telle que:\n",
        "\n",
        "* Computer vision\n",
        "  * réseaux de neurones convolutifs\n",
        "* NLP\n",
        "* Modèles multimodaux\n",
        "* deep learning\n",
        "\n",
        "Bien que ce projet utilise le dataset d'un site de vente, il est assez générique de par la nature de son sujet qui pourrait se résumer ainsi: Attribuer une classe à un objet à partir d'une description textuelle et d'une image. On pourrait imaginer toutes sortes de déclinaisons:\n",
        "\n",
        "* Commerciales\n",
        "  * Classification automatique de produits mis en vente sur un site de e-commerce (le but original du challenge).\n",
        "    * Assister un utilisateur dans le choix d'une catégorie lors de la mise en vente de son produit. Quand on connaît le grand nombre de catégories typiquement proposées sur les sites de e-commerce, on peut imaginer la confusion des utilisateurs.\n",
        "    * On pourrait même imaginer un système plus coercitif qui impose une catégorie en fonction du contenu pour éviter les erreurs de catégorisation.\n",
        "    * Fournir une recherche intelligente des produits qui puisse automatiquement traduire une description de produit saisie en classe de produits et ainsi produire des résultats pertinents.   \n",
        "* Génériques\n",
        "  * Un moteur de recherche d'objets à partir de description ou même d'images.\n",
        "  * Moteur de recherche d'image à partir d'une description et réciproquement (si les modèles individuels de nlp et de computer vision sont suffisamment performant)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCka46UC-RII"
      },
      "source": [
        "## Equipe\n",
        "\n",
        "* Mathis Poignet: TODO\n",
        "* Karim Hadjar: TODO\n",
        "* Julien Noel du Payrat ([GitHub](https://github.com/surfncode) / [LinkedIn](https://www.linkedin.com/in/julien-noel-du-payrat-01854558))\n",
        "  * J'ai un background de développeur depuis plus de 15 ans, en revanche, je fais encore mes armes en data science. Malgré une curiosité naturelle pour ce domaine, c'est quelque chose que j'ai découvert pendant la formation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sDxLpJZtvaH"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocke3vFsuQ3k"
      },
      "source": [
        "## Montage du projet\n",
        "Accès au dossier du projet sur Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JU0Rqbjk8G_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "%cd drive/MyDrive/Projet_Rakuten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdUnOfdun02"
      },
      "source": [
        "## Initialisation des variables globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQpL_4gVum-f"
      },
      "outputs": [],
      "source": [
        "random_state = 123\n",
        "# TODO: est-ce qu'on utilise ça ?\n",
        "label2categorie = {\n",
        "    10\t:\t\"Livres\",\n",
        "    40\t:\t\"Gaming\",\n",
        "    50\t:\t\"Gaming\",\n",
        "    60\t:\t\"Gaming\",\n",
        "    1140\t:\t\"Jouets\",\n",
        "    1160\t:\t\"Jouets\",\n",
        "    1180\t:\t\"Jouets\",\n",
        "    1280\t:\t\"Jouets\",\n",
        "    1281\t:\t\"Jouets\",\n",
        "    1300\t:\t\"Jouets\",\n",
        "    1301\t:\t\"Bazar\",\n",
        "    1302\t:\t\"Jouets\",\n",
        "    1320\t:\t\"Equipement\",\n",
        "    1560\t:\t\"Mobilier\",\n",
        "    1920\t:\t\"Décoration\",\n",
        "    1940\t:\t\"Bazar\",\n",
        "    2060\t:\t\"Décoration\",\n",
        "    2220\t:\t\"Equipement\",\n",
        "    2280\t:\t\"Livres\",\n",
        "    2403\t:\t\"Livres\",\n",
        "    2462\t:\t\"Gaming\",\n",
        "    2522\t:\t\"Livres\",\n",
        "    2582\t:\t\"Mobilier\",\n",
        "    2583\t:\t\"Equipement\",\n",
        "    2585\t:\t\"Equipement\",\n",
        "    2705\t:\t\"Livres\",\n",
        "    2905\t:\t\"Gaming\",\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6liw5iYTuJyj"
      },
      "source": [
        "## Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LevBTAn6lKE"
      },
      "outputs": [],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRmIduE1gqNB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from tqdm import tqdm\n",
        "import html\n",
        "\n",
        "from langdetect import detect_langs\n",
        "# Force langdetect to have deterministic results\n",
        "from langdetect import DetectorFactory\n",
        "DetectorFactory.seed = random_state\n",
        "\n",
        "# Télécharger et utiliser les stopwords français (STOPWORDS pour l'anglais)\n",
        "from wordcloud import WordCloud #, STOPWORDS\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CPBkTKSiikd"
      },
      "source": [
        "## Chargement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R75BlvQXi-pK"
      },
      "source": [
        "Chargeons X_train.csv et affichons un premier aperçu des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReqHTb2WugHv"
      },
      "outputs": [],
      "source": [
        "X = pd.read_csv('Datasets/X_train.csv', index_col=0)\n",
        "X.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlcLzvicwWrD"
      },
      "outputs": [],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeJvJrjUkU89"
      },
      "source": [
        "Ce premier coup d'œil nous montre que comme il fallait s'y attendre pour un champ optionnel, le champ **description** contient un grand nombre de valeurs nulles. Nous reviendrons là dessus...\n",
        "Les autres colonnes ne contiennent pas de valeurs nulles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE08AxPAy9Jq"
      },
      "source": [
        "Chargeons maintenant Y_train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-bVE6VyzELm"
      },
      "outputs": [],
      "source": [
        "Y = pd.read_csv(\"Datasets/Y_train.csv\",index_col=0)\n",
        "display(Y.head(10))\n",
        "\n",
        "display(Y.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWgZSD5rzex3"
      },
      "source": [
        "On voit qu'il n'y a pas de valeurs manquantes et que les deux fichiers **X_train.csv**, **Y_train.csv** ont bien le même nb d'entrées.\n",
        "\n",
        "On va maintenant réunir les variables explicatives et la variable cible dans un même DataFrame **df** pour faciliter nos explorations. Au passage ça nous permettra de vérifier qu'on a bien une correspondance totale entre les deux indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc3gSSBC0AAU"
      },
      "outputs": [],
      "source": [
        "df = X.join(Y,how='inner')\n",
        "if df.shape[0] == X.shape[0] or df.shape[0] == Y.shape[0]:\n",
        "  print(\"\"\"\n",
        "  Tous les fichiers ainsi que leur inner merge ont bien le même nombre\n",
        "  d'entrées\n",
        "  \"\"\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UdN_m5o0sdd"
      },
      "source": [
        "On constate que le merge s'est bien passé. On a maintenant un DataFrame **df** rattachant les variables de **X** et la colonne cible **prdtypecode**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5NxCPml9O7u"
      },
      "source": [
        "# Exploration des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibGXs6SVpwi"
      },
      "source": [
        "## Vérification des doublons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSwSpmamVulD"
      },
      "source": [
        "Vérifions que le dataset ne contient pas de doublons de lignes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z66ppkuV48a"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRncMKlwWb7m"
      },
      "source": [
        "Il n'y a pas de lignes dupliquées.\n",
        "\n",
        "Vérifions maintenant les doublons pour chaque variable explicative séparément"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN3bp7S3VoyR"
      },
      "outputs": [],
      "source": [
        "print(\"doublons de designation : \",df['designation'].duplicated().sum())\n",
        "print(\"doublons de description : \",df['description'].duplicated().sum())\n",
        "print(\"doublons de productid : \", df['productid'].duplicated().sum())\n",
        "print(\"doublons de imageid : \", df['imageid'].duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3ApfS3XXCC"
      },
      "source": [
        "2651 doublons apparaissent pour **designation**. Même si le nombre n'est pas anodin, il pourrait s'expliquer par le des copié collé de la désignation au moment de mettre un produit en vente sur le site de Rakuten.\n",
        "\n",
        "Le nombre de doublons de **description** est plus préoccupant, il semble vraiment élevé pour un champ avec des textes aussi longs. Assurons nous que les na n'ont pas été comptés comme doublons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeWYyPMUYWle"
      },
      "outputs": [],
      "source": [
        "df[df['description'].isna() == False][\"description\"].duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaI2KqQ4ZNNQ"
      },
      "source": [
        "Après avoir éliminé les na, il ne reste plus que 7610 doublons. C'est déjà mieux.\n",
        "\n",
        "Tentons maintenant de repérer combien parmi ces doublons de **designation** et **description** sont communs aux deux variables réunies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zeRMqDIZ8wX"
      },
      "outputs": [],
      "source": [
        "des_descr_duplicates = df[['designation','description']][df['description'].isna() == False].duplicated().sum()\n",
        "des_descr_duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgS-n5g_aVvS"
      },
      "source": [
        "1294 produits, bien qu'ayant des productid, ont des couples **designation**, **description** communs.\n",
        "\n",
        "On peut donc obtenir maintenant le compte réel des doublons pour les colonnes traitées séparément."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKo-eBbcbFJg"
      },
      "outputs": [],
      "source": [
        "print(\"doublons des colonnes en enlevant les doublons communs\")\n",
        "print(\"designation : \",df['designation'].duplicated().sum() - des_descr_duplicates)\n",
        "print(\"description : \"\n",
        "  ,df[df['description'].isna() == False][\"description\"].duplicated().sum() - des_descr_duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1bJoJZob7f3"
      },
      "source": [
        "Le nombre de doublon est assez important et on ne peut pas les supprimer sans réfléchir. Il va falloir évaluer leur répartition en regard de la variable cible pour se décider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_QQWi167G3v"
      },
      "source": [
        "## Analyse de la variable cible (**prdtypecode**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPouffuuFIWu"
      },
      "source": [
        "Commençons par compter le nombre de classes possibles que peut prendre la variable cible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLWVDyLDFQPl"
      },
      "outputs": [],
      "source": [
        "print(\"La variable cible compte %d classes possibles\" % df[\"prdtypecode\"].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC-hcroVhZog"
      },
      "source": [
        "Regardons maintenant le nombre de produits de chaque type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeGNZhhH304b"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (16, 4))\n",
        "sns.countplot(x = df['prdtypecode'], order = df['prdtypecode'].value_counts().index)\n",
        "plt.title('Nombre de produits par type')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSGMlDlSGoI9"
      },
      "source": [
        "On constate que certaines classes (à droite du graphique) comme la classe **60** sont sous-représentées. Au contraire, la classe **2583** compte environ deux fois plus d'instances que les classes adjacentes à sa droite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpaN69x-uc3u"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (16, 4))\n",
        "# Identifier les doublons dans 'description' qui ne sont pas NaN\n",
        "df_doublons = df[(df['description'].isna() == False) & (df[df['description'].isna() == False][\"description\"].duplicated(keep = False))]\n",
        "\n",
        "# Compter et afficher le nombre de doublons par catégorie 'prdtypecode'\n",
        "sns.countplot(x = df_doublons['prdtypecode'], order = df_doublons['prdtypecode'].value_counts().index)\n",
        "plt.title('Nombre de doublons désignation / description par type')\n",
        "plt.show();\n",
        "\n",
        "\n",
        "print(\"\\n Nombre de doublons par designation\")\n",
        "print(df_doublons['designation'].value_counts())\n",
        "print(\"\\n Nombre de doublons par description\")\n",
        "df_doublons['description'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBiJLm1Wuj3n"
      },
      "source": [
        "La répartition des doublons est assez similaire à la répartition des produits par rapport à la variable cible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "papLSTw2unN7"
      },
      "source": [
        "On pourrait donc décider de supprimer les doublons sans casser la répartition initiale. Mais est-ce gênant de les garder? (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDGBp-quHOQp"
      },
      "source": [
        "Les type codes ne sont pas très parlants si on veut se faire une idée du contenu des classes. Nous sommes parvenus à trouver sur (TODO: lien vers la source) les labels correspondants aux différents codes.\n",
        "\n",
        "Pour la suite, nous allons construire un dictionnaire nous permettant d'associer les codes à leurs labels respectifs afin que les visuels gagnent en clarté."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0cO1_njIMsM"
      },
      "outputs": [],
      "source": [
        "prdcodetype2label = {\n",
        "    10 : \"Livre occasion\",\n",
        "    40 : \"Jeu vidéo, accessoire tech.\",\n",
        "    50 : \"Accessoire Console\",\n",
        "    60 : \"Console de jeu\",\n",
        "    1140 : \"Figurine\",\n",
        "    1160 : \"Carte Collection\",\n",
        "    1180 : \"Jeu Plateau\",\n",
        "    1280 : \"Jouet enfant, déguisement\",\n",
        "    1281 : \"Jeu de société\",\n",
        "    1300 : \"Jouet tech\",\n",
        "    1301 : \"Paire de chaussettes\",\n",
        "    1302 : \"Jeu extérieur, vêtement\",\n",
        "    1320 : \"Autour du bébé\",\n",
        "    1560 : \"Mobilier intérieur\",\n",
        "    1920 : \"Chambre\",\n",
        "    1940 : \"Cuisine\",\n",
        "    2060 : \"Décoration intérieure\",\n",
        "    2220 : \"Animal\",\n",
        "    2280 : \"Revues et journaux\",\n",
        "    2403 : \"Magazines, livres et BDs\",\n",
        "    2462 : \"Jeu occasion\",\n",
        "    2522 : \"Bureautique et papeterie\",\n",
        "    2582 : \"Mobilier extérieur\",\n",
        "    2583 : \"Autour de la piscine\",\n",
        "    2585 : \"Bricolage\",\n",
        "    2705 : \"Livre neuf\",\n",
        "    2905 : \"Jeu PC\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZwy0Cx4IfhV"
      },
      "source": [
        "Ajoutons une colonne **categorie** à **df**. Celle ci va contenir le label associé au **prdtypecode**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiY--o4KIeTn"
      },
      "outputs": [],
      "source": [
        "df['categorie'] = df['prdtypecode'].map(prdcodetype2label)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98_wztyHMaVF"
      },
      "source": [
        "## Valeurs nulles de **description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su9O4pVPJw8D"
      },
      "source": [
        "Intéressons nous maintenant aux valeurs nulles de la variable **description** que nous avons remarqué lors du chargement des données.\n",
        "\n",
        "Calculons déjà leur proportion par rapport aux données totales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XdXg7PNPBVj"
      },
      "outputs": [],
      "source": [
        "print(\"Les nan de descriptions représentent %d%% des données\" \\\n",
        "      % (df['description'].isna().sum() * 100 / df.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPuYrrxkO0Mi"
      },
      "source": [
        "Commençons à réfléchir à que faire de ces nans. On peut déjà envisager plusieurs options:\n",
        "* On pourrait simplement supprimer les lignes qui en contiennent même si ça représente tout de même une part importante des données. De plus, cela viendrait en quelque sorte à l'encontre de l'objectif du projet qui spécifie bien que la colonne **description** est optionnelle. On doit donc prendre ça en compte dans notre approche\n",
        "* On pourrait les remplacer par des chaînes de caractères vides. Bien que cette possibilité semble simple, nous avons beaucoup d'incertitudes quant à l'impact que ça aurait sur les modèles de prédictions.\n",
        "* Sachant que le champ **designation** n'est jamais vide, on pourrait ajouter une troisième variable qui soit la concaténation des champs **designation** et **description**. Ainsi, cette nouvelle variable contiendrait au moins le contenu du champ **designation** nous ôtant ce problème de nan.\n",
        "\n",
        "A première vue, c'est la troisième option qui semble la plus judicieuse, toutefois, pour essayer d'y voir plus clair, affichons un graphique en barre qui permettent de voir la proportion de nan pour chaque type de produit\n",
        "\n",
        "Maintenant que nous avons des labels, on peut s'en servir plutôt que d'afficher des codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V78WQwgJvjh"
      },
      "outputs": [],
      "source": [
        "# Transforme la colonne categorie en string\n",
        "df.categorie = df.categorie.astype(str)\n",
        "\n",
        "# Calcul du nombre d'apparitions de chaque catégorie\n",
        "category_counts = df['categorie'].value_counts()\n",
        "\n",
        "# Calcul des pourcentages de NaN et non-NaN pour chaque catégorie\n",
        "category_nan_counts = df.groupby('categorie')['description'].apply(lambda x: x.isna().sum())\n",
        "category_non_nan_counts = df.groupby('categorie')['description'].apply(lambda x: x.notna().sum())\n",
        "\n",
        "\n",
        "# Tri des catégories par nombre d'apparitions\n",
        "sorted_categories = category_counts.index.tolist()\n",
        "\n",
        "# Tri des pourcentages de NaN et non-NaN selon l'ordre des catégories\n",
        "sorted_nan_counts = category_nan_counts.reindex(sorted_categories)\n",
        "sorted_non_nan_counts = category_non_nan_counts.reindex(sorted_categories)\n",
        "\n",
        "# Création du graphique en barres\n",
        "fig = go.Figure()\n",
        "\n",
        "# Ajout des barres pour les valeurs non-NaN\n",
        "fig.add_trace(go.Bar(\n",
        "    name='Non-NaN',\n",
        "    x=sorted_categories,\n",
        "    y=sorted_non_nan_counts,\n",
        "    marker_color='green'\n",
        "))\n",
        "\n",
        "# Ajout des barres pour les valeurs NaN\n",
        "fig.add_trace(go.Bar(\n",
        "    name='NaN',\n",
        "    x=sorted_categories,\n",
        "    y=sorted_nan_counts,\n",
        "    marker_color='red'\n",
        "))\n",
        "\n",
        "# Mise à jour des paramètres du layout\n",
        "fig.update_layout(\n",
        "    barmode='stack',\n",
        "    title='Répartition des NaN dans la Description par Catégorie',\n",
        "    xaxis_title='Catégorie',\n",
        "    yaxis_title='Pourcentage'\n",
        ")\n",
        "\n",
        "fig.update_xaxes(tickangle=60)\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eXn9i63OB8q"
      },
      "source": [
        "\n",
        "Cela nous confirme que l'option 1 est inenvisageable. Supprimer les lignes dont la **description** est vide revient presque à supprimer certaines catégories.\n",
        "On préférera l'option 3: concaténer les champs **designation** et **description**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmgEV7gPfMPC"
      },
      "source": [
        "## Longueur des textes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1a0kycl66Rs"
      },
      "source": [
        "Nous n'avons pas encore parlé du type de texte qu'on peut trouver dans **designation** et **description**.\n",
        "\n",
        "Penchons-nous sur la longueur des textes qu'on peut y trouver."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IPKA7JE6-Jz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(121)\n",
        "sns.boxplot(df['designation'].str.len().values)\n",
        "plt.xlabel(\"designation\")\n",
        "plt.xticks([])\n",
        "plt.subplot(122)\n",
        "# On pense à enlever les na de description pour ne pas fausser les stats\n",
        "sns.boxplot(data=df['description'][df['description'].isna()==False].str.len().values)\n",
        "plt.xlabel(\"description\")\n",
        "plt.xticks([])\n",
        "plt.suptitle(\"Distribution des longueurs de texte (en nb de caractères)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpz_iXz0EJw8"
      },
      "source": [
        "Comme il fallait s'y attendre, on constate que les longueurs de texte dans **description** sont largement supérieures à celles qu'on trouve dans **designation**.\n",
        "\n",
        "Dans les deux cas, on note un grand nombre d'outliers au dessus de l'interval interquartile `q3 + (q3 - q1 * 1.5)`. La distribution des outliers pour **description** est particulièrement étendue vers le haut puisqu'elle monte jusqu'à plus de 12,000 caractères alors que la valeur la plus haute située dans la fourchette *typique* se situe vers 2000.\n",
        "\n",
        "Un autre information importante apparaît. Il semble qu'il y ait un certain nombre de valeurs proches de zéro caractères. Pour tenter d'y voir plus clair affichons le nombre de d’occurrences de **description** ayant une longueur inférieure à 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pRIRe6THlLS"
      },
      "outputs": [],
      "source": [
        "df[df['description'].str.len() < 5]['description'].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6t8LiAjH7aK"
      },
      "source": [
        "Seules 70 **descriptions** ont une longueur inférieure à 5. Ce cas reste minoritaire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQidZpYE_JxY"
      },
      "source": [
        "## HTML dans les données textuelles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii11l9S8KPI1"
      },
      "source": [
        "En parcourant les données tabulaires de **X_train.csv**, on s'aperçoit qu'un grand nombre de textes contiennent du HTML, soit sous forme de tags, soit sous forme d'entités. Par exemple, on trouve des **description** comme ceci:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHW4mSdiKnrC"
      },
      "outputs": [],
      "source": [
        "df.iloc[36]['description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkJu6qgPknPf"
      },
      "source": [
        "On constate la présence de plusieurs tags HTML dans le texte notamment `<b></b>` et `<p></p>`\n",
        "\n",
        "En outre, le texte contient également des caractères encodés sous la forme d'entités html `&#xx;` où xx représente deux digits en base hexadécimal. Par exemple `&#39;` représente une apostrophe. D'autres exemples dans le dataset contiennent des entités au format: `&<symbol-name>;` comme `&amp;` qui représente le caractère `&`.\n",
        "\n",
        "Tentons, d'en savoir plus sur la fréquence de **description** contenant du HTML et/ou des entités"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRK1ybgYpUb5"
      },
      "outputs": [],
      "source": [
        "regex_tags = re.compile('<.*?>')\n",
        "regex_entities = re.compile('&(?:#\\d+|\\w+);')\n",
        "\n",
        "description_without_na = df['description'][df['description'].isna() == False]\n",
        "has_entities = description_without_na.str.contains(regex_entities)\n",
        "has_html = description_without_na.str.contains(regex_tags)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.suptitle(\"Proportion de descriptions avec des tags ou des entités HTML (hors NA)\")\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.pie([has_html.sum(),description_without_na.shape[0]]\n",
        "        ,labels=['Avec tags','Sans tags']\n",
        "       ,explode=[0.2,0]\n",
        "       ,autopct = lambda p : (\"%.2f%%\" % p)\n",
        "       ,pctdistance = 0.7\n",
        "       ,labeldistance=1.2\n",
        "       ,shadow=True)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.pie([has_entities.sum(),description_without_na.shape[0]]\n",
        "        ,labels=['Avec entités','Sans entités']\n",
        "       ,explode=[0.2,0]\n",
        "       ,autopct = lambda p : (\"%.2f%%\" % p)\n",
        "       ,pctdistance = 0.7\n",
        "       ,labeldistance=1.2\n",
        "       ,shadow=True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdkDUHqzk-nt"
      },
      "source": [
        "Ici, on peut voir qu'une proportion significative de **descriptions** contient des tag ou entités HTML.\n",
        "\n",
        "**designation** contient-il, lui aussi du HTML ? Tentons de répondre à cette question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq6Klp5zhsnn"
      },
      "outputs": [],
      "source": [
        "has_html = df['designation'].str.contains(regex_tags)\n",
        "has_html.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F487G740l5rf"
      },
      "source": [
        "Seule une **designation** semble contenir des tags HTML. Cela semble curieux. Examinons son contenu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzqyE-egw8nz"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[has_html[has_html].index[0]]['designation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXScwWhKxRHS"
      },
      "source": [
        "La ligne est assez longue mais on peut voir que ce qu'on prenait pour un tag HTML n'est est pas un: `<Att>`\n",
        "\n",
        "Maintenant, regardons si *designation* contient des entités HTML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxjOPCt_x4jm"
      },
      "outputs": [],
      "source": [
        "has_entities = df['designation'].str.contains(regex_entities)\n",
        "has_entities.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtL5pYSzy9gD"
      },
      "source": [
        "990 occurrences de **designation** contiennent des entités html. C'est relativement peu.\n",
        "\n",
        "Nous désirons commencer à examiner les langues ainsi que la fréquence des mots. Les éléments HTML que nous avons trouvés risquent de nous gêner dans ces tâches. Pour nous faciliter la tâche nous allons les supprimer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyn8hP0ct6dP"
      },
      "source": [
        "Créons une fonction qui va permettre de supprimer les tags HTML et remplacer les entités par leur caractères normaux."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVBZ4NwY4YGV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def clean_html_stuff(col):\n",
        "  regex_tags_nl = re.compile('<\\s*(?:br|p|li)\\s?.*?>',flags=re.IGNORECASE)\n",
        "  regex_tags_space = re.compile('<.*?>')\n",
        "\n",
        "  new_col = []\n",
        "  for text in tqdm(col):\n",
        "    if not pd.isnull(text):\n",
        "      # remplacement de certains tags par '\\n'\n",
        "      # Ca permet de conserver un peu de la structure du texte au cas\n",
        "      # où les modèles de nlp et/ou deep learning y soit sensibles\n",
        "      # (c'est aussi plus agréable à l'oeil)\n",
        "      text = re.sub(regex_tags_nl,'\\n',text)\n",
        "      # remplacement des tags restants par des espaces\n",
        "      # J'ai choisi un espace plutôt qu'une chaine vide\n",
        "      # pour éviter de concaténer des mots par erreur.\n",
        "      # Ex remplacement par chaine vide:\n",
        "      # \"info<span>importante</span>\" => \"infoimportante\"\n",
        "      # Ex remplacement par espace\n",
        "      # \"info<span>importante</span>\" => \"info importante \"\n",
        "      # Ca produit quelques espaces en plus mais ça ne devrait pas poser\n",
        "      # de problèmes\n",
        "      text = re.sub(regex_tags_space,' ',text)\n",
        "      # J'ai choisi de faire le remplacement des entité html après celui des tags\n",
        "      # pour eviter le scenario ci-dessous\n",
        "      # Remplacement avant tags:\n",
        "      # \"Enceinte &lt; 5kg et &gt; 8DB\" => \"Enceinte 8DB\"\n",
        "      # Remplacement après tags:\n",
        "      # \"Enceinte &lt; 5kg et &gt; 8DB\" => \"Enceinte < 5kg et > 8DB\"\n",
        "      # L'inconvénient en revanche, c'est que quelques tag qui étaient\n",
        "      # encodés avec des &lt; &gt; subsitent mais ils sont peu\n",
        "      # nombreux sur le volume des données\n",
        "      text = html.unescape(text)\n",
        "    new_col.append(text)\n",
        "\n",
        "  return new_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeaVO0uv25G1"
      },
      "source": [
        "Nous pouvons maintenant appliquer cette fonction aux variables **designation** et **description**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFSN1xYx24QK"
      },
      "outputs": [],
      "source": [
        "df['designation'] = clean_html_stuff(df['designation'])\n",
        "df['description'] = clean_html_stuff(df['description'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rDUekywrwjS"
      },
      "source": [
        "## Analyse des langues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlP2wlDn5CrF"
      },
      "source": [
        "En parcourant les données, on peut constater qu'hormis du HTML les données textes semblent être dans plusieurs langues. Beaucoup semblent rédigées en français mais on trouve également de l'anglais et de l'allemand dans des proportions non négligeables. Il pourrait aussi y avoir d'autres langues que nous n'avons pas remarqué, le volume de données étant important.\n",
        "\n",
        "Pour tenter d'y voir plus clair, on peut recourir à la librairie **langdetect** qui permet de détecter la langue la plus probable d'un texte. Selon la documentation, plus le texte est long, plus la fiabilité de la détection augmente. Commençons donc par créer ajouter une variable **text** qui sera la concaténation de **designation** et **description**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foixFDmn3USW"
      },
      "outputs": [],
      "source": [
        "df['description'] = df['description'].fillna('')\n",
        "df['text'] = df['designation'] + \" - \" + df['description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5X1UyaVs9Wp"
      },
      "source": [
        "Nous pouvons maintenant procéder à la détection des langues sur cette la variable **text**. Nous allons ajouter deux colonnes: **lang** et **lang_prob** contenant respectivement le code à 2 lettres du langage (fr,en,de etc...) et la probabilité que cette langue ait été détectée correctement.\n",
        "\n",
        "Comme cette détection est lente, nous sauvegardons son résultat dans un fichier csv **Output/data-exploration/lang.csv**. Ainsi, si ce fichier est présent, les executions suivantes de cette cellule n'auront pas à refaire la détection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8vX6kDR3LsF"
      },
      "outputs": [],
      "source": [
        "if 'lang' in df.columns:\n",
        "  df.drop(['lang'],axis=1,inplace=True)\n",
        "if 'lang_prob' in df.columns:\n",
        "  df.drop(['lang_prob'],axis=1,inplace=True)\n",
        "\n",
        "output_dir = \"Output/data-exploration\"\n",
        "lang_file_path = output_dir + \"/lang.csv\"\n",
        "lang_file = Path(lang_file_path)\n",
        "if lang_file.exists():\n",
        "  print(\"chargement du fichier existant:\",lang_file_path)\n",
        "  lang_df = pd.read_csv(lang_file_path,index_col=0)\n",
        "\n",
        "else :\n",
        "  print(\"detection des langues\")\n",
        "  lang_text = []\n",
        "  lang_text_prob = []\n",
        "  for text in tqdm(df['text']):\n",
        "    detected_langs = detect_langs(text)\n",
        "    if len(detected_langs) > 0:\n",
        "      lang_text.append(detected_langs[0].lang)\n",
        "      lang_text_prob.append(detected_langs[0].prob)\n",
        "    else:\n",
        "      lang_text.append(np.NaN)\n",
        "      lang_text_prob.append(np.NaN)\n",
        "\n",
        "  lang_df = pd.DataFrame(index=df.index,columns=['lang','lang_prob'])\n",
        "  lang_df['lang'] = lang_text\n",
        "  lang_df['lang_prob'] = lang_text_prob\n",
        "  print(\"sauvgarde dans le fichier:\",lang_file_path)\n",
        "  Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "  lang_df.to_csv(lang_file_path)\n",
        "\n",
        "\n",
        "\n",
        "df = df.join(lang_df,how=\"inner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1KvqHhTDX-q"
      },
      "source": [
        "Affichons maintenant **df** avec les nouvelles colonnes issues de la détection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C88Wrd5VB2nd"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpS5v02TDllO"
      },
      "source": [
        "On voit que la détection semble avoir fonctionné. A première vue, la fiabilité de la détection est excellente mais vérifions tout de même sur l'ensemble des données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0id40AWDoBj"
      },
      "outputs": [],
      "source": [
        "df['lang_prob'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp4N51Ma88MT"
      },
      "source": [
        "On observe que les probabilités de détection correctes sont en général très bonnes. Dès le premier quartile (25%), on a déjà une probabilité d'à peu près 0.99. La moyenne de 95% et la médiane de 99.9% nous confirme qu'on peut avoir confiance en la détection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3KFlyz89Mqk"
      },
      "source": [
        "Le code de la détection peut produire des valeurs nulles si aucune langue n'a pu être détectée par **langdetect**, vérifions que ce n'est pas le cas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQCpU1EVDbQY"
      },
      "outputs": [],
      "source": [
        "df[['lang','lang_prob']].info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8w6Uz8q9jt6"
      },
      "source": [
        "On voit que ni **lang**, ni **lang_prob**  ne contiennent de valeurs manquantes.\n",
        "\n",
        "On peut supprimer la colonne **lang_prob** maintenant que nous sommes rassurés sur la qualité de la détection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwqBctXS-Ojp"
      },
      "outputs": [],
      "source": [
        "df.drop('lang_prob',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elFVQUcJKydD"
      },
      "source": [
        "Maintenant que nous avons une langue pour chaque observation, on peut examiner la répartition des contenus par langue. Observons ça sur un graphique en barres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0bjy2nhFKmL"
      },
      "outputs": [],
      "source": [
        "# Calcul du nombre de valeurs\n",
        "total = df['lang'].value_counts().sum()\n",
        "# Calcul du cumul des valeurs\n",
        "cumul = df['lang'].value_counts().cumsum() / total *100\n",
        "\n",
        "# graphique en barres avec les comptes par langue\n",
        "fig, ax1 = plt.subplots(figsize = (12, 4))\n",
        "sns.countplot(x = df.lang, order = df.lang.value_counts().index, ax = ax1)\n",
        "\n",
        "# Création d'un deuxième axe y pour le cumul\n",
        "ax2 = ax1.twinx()\n",
        "# Ligne de cumul sur le deuxième axe y\n",
        "ax2.plot(cumul.index, cumul.values, color='red', marker='o', linestyle='-', linewidth=2)\n",
        "ax2.set_ylabel('Cumul')\n",
        "# Ajustement de l'échelle du deuxième axe\n",
        "ax2.set_ylim(0, cumul.values[-1])\n",
        "\n",
        "plt.title('Nombre de contenus par langues détectés')\n",
        "# Afficher la grille seulement pour le deuxième axe y\n",
        "ax2.grid(None)\n",
        "ax1.grid(None)\n",
        "ax1.yaxis.grid(None)\n",
        "ax2.yaxis.grid(True)\n",
        "# Ajout annotations\n",
        "plt.text(cumul.index[2], cumul.values[2] - 10, str(round(cumul.values[2],1)), ha='center', va='bottom')\n",
        "plt.text(cumul.index[4], cumul.values[4] - 10, str(round(cumul.values[4],1)), ha='center', va='bottom')\n",
        "plt.text(cumul.index[6], cumul.values[6] - 10, str(round(cumul.values[6],1)), ha='center', va='bottom')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCnP5EaOPPCp"
      },
      "source": [
        "On observe que le dataset ne compte pas moins de 16 langues. Cependant la plupart sont extrêmement minoritaires. Trois langues sont largement majoritaires: Le français, l'anglais puis l'allemand. A elles seules, elles représentent plus de 95% du contenu.\n",
        "\n",
        "La répartition parmi ces trois langues est également hétéroclite puisque le français compte déjà pour plus de 75% suivi de très loin par l'anglais qui compte pour 5 fois moins et enfin de l'allemand représentant à peu près 1/3 du contenu anglais.\n",
        "\n",
        "Pour se faire une idée plus juste des proportions. Observons la répartition des langues sur un camembert. On considérera que les langues qui ne font pas partie d'une des trois plus fréquentes peuvent être reléguées dans une catégorie autre afin de ne pas nuire à la lisibilité du graphique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRJitSQNK-GE"
      },
      "outputs": [],
      "source": [
        "lang_simple = df['lang']\n",
        "# On obtients la liste des langues minoritaires en excluant les trois\n",
        "# majoritaires puis on les remplace par \"other\" pour ne pas surcharger le graph\n",
        "other_langs = df['lang'].value_counts().index[3:]\n",
        "lang_simple = lang_simple.replace(other_langs,\"other\")\n",
        "lang_counts = lang_simple.value_counts()\n",
        "\n",
        "# Créer le diagramme en camembert avec Plotly\n",
        "fig = go.Figure(data=[go.Pie(labels=lang_counts.index, values=lang_counts.values)])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ygwIlOOPc5A"
      },
      "source": [
        "On retrouve d'une façon plus explicite les chiffres qu'on a vu sur le graphique en barres. Le français en tête avec 77% suivi de l'anglais comptant pour 15% puis de l'allemand avec 3%. Quant au cumul des autres langues, il atteint à peine 5%.\n",
        "\n",
        "La plupart des modèles ne NLP fonctionnent avec l'anglais. Bien qu'il y ait des versions adaptées pour le français, ça reste des modèles différents. Admettons qu'on veuille résoudre ce problème de classification pour le français et l'anglais séparément en omettant les autres langues minoritaires, ça pourrait impliquer de doubler la charge de travail.\n",
        "\n",
        "Une autre technique consisterait à ne conserver que le contenu français cependant ça représenterait tout de même une perte de données de 25% environ. Avant de considérer cette alternative, vérifions la répartition des langues par type de produit. On ne peut se permettre de supprimer une langue si celle-ci représente une part importante des observations pour un type de produit.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ek8bfWDLrM_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.displot(y=df['categorie'],hue=lang_simple,multiple=\"stack\",aspect=1.7,binwidth=2)\n",
        "plt.title(\"Repartition des langues par types de produit\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pqWKB4yzSTA"
      },
      "source": [
        "Un point rassurant est que le français constitue la majorité (relative et non absolue) dans chaque type de produit. Cependant on observe quand même que pour certains types comme *jeu de plateau* cette majorité relative est ténue. Retirer les autres langues alors que le nombre de produits y est déjà faible pourrait produire un déséquilibre dans la distribution des classes de produits et compromettre la fiabilité de la classification.\n",
        "\n",
        "Une autre technique qui éviterait ces écueils consisterait à traduire toutes les langues vers le français. La faisabilité reste encore à expérimenter sur un dataset de cette taille mais ça vaudra la peine de s'y pencher pendant la phase de pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H4DFav2Vydw"
      },
      "source": [
        "## Fréquence des mots sur **designation** et **text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0aLsGfENAfN"
      },
      "source": [
        "Une façon d'approfondir notre analyse des données consiste à observer la fréquence des mots contenus dans les variables textuelles.\n",
        "\n",
        "Ajoutons deux colonnes **mots_designation** et **mots_text** qui vont contenir la liste des mots extraits depuis leur colonne respective **designation** et **text**. Étudier séparément chacune de ces colonnes devrait nous permettre de souligner les différences entre la fréquence globale des mots et celle de **designation**.\n",
        "\n",
        "On procède à l'extraction des mots par une *tokenization maison* à base d'expressions régulières tout en étant vigilant à exclure les mots qui apportent peu d'informations à notre analyse fréquentielle.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsY4V_5mlRIq"
      },
      "outputs": [],
      "source": [
        "# Création d'une liste personnalisée de stopwords français, anglais et allemends\n",
        "french_stopwords = set(nltk_stopwords.words('french'))\n",
        "english_stopwords = set(nltk_stopwords.words('english'))\n",
        "dutch_stopwords = set(nltk_stopwords.words('dutch'))\n",
        "combined_stopwords = french_stopwords.union(english_stopwords)\n",
        "\n",
        "# Fonction pour nettoyer et extraire les mots, en excluant les stopwords\n",
        "def extract_words(text):\n",
        "    # Utilisation d'une expression régulière pour ne conserver que les mots\n",
        "    words = re.findall(r'\\w+', text.lower())\n",
        "    # Filtrage des mots en excluant les stopwords, les chiffres et les mots de moins de 3 lettres, et suppression des doublons\n",
        "    unique_words = {word for word in words if word not in combined_stopwords and not word.isdigit() and len(word) > 2}\n",
        "    return list(unique_words)\n",
        "\n",
        "# Ajout colonne mots_designation contenant les mots de la colonne designation\n",
        "df['mots_designation'] = df['designation'].apply(extract_words)\n",
        "# Ajout colonne text contenant les mots de la colonne description\n",
        "df['mots_text'] = df['text'].apply(extract_words)\n",
        "\n",
        "# Affichage du résultat\n",
        "display(df.head())\n",
        "display(df['text'][0])\n",
        "df['mots_text'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L89O2-FgQwfu"
      },
      "source": [
        "L'extraction s'est bien déroulée, on constate l'apparition des deux nouvelles colonnes **mots_designation** et **mots_text**.\n",
        "\n",
        "On peut désormais afficher un premier nuage de mots qui représente la fréquence des mots contenus dans **designation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe94NX4UNGkw"
      },
      "outputs": [],
      "source": [
        "# Génération du nuage de mots\n",
        "# Création de la chaine all_word_designation en combinant toutes les listes de mots\n",
        "all_word_designation = ' '.join([word for words_list in df['mots_designation'] for word in words_list])\n",
        "\n",
        "wordcloud_designation = WordCloud(width = 800, height = 800, max_words = 1000, background_color = 'black',\n",
        "                      colormap = \"nipy_spectral\").generate(all_word_designation)\n",
        "\n",
        "plt.imshow(wordcloud_designation)\n",
        "plt.axis(\"off\")\n",
        "plt.title('Mots contenus dans la designation')\n",
        "plt.tight_layout(pad=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJyidN4KRfxT"
      },
      "source": [
        "On observe une nette prédominance des mots français en accord avec nos observations sur la répartition des langues. On a peine à distinguer quelques mots d'anglais en arrière-plan.\n",
        "\n",
        "Quelques mots se distinguent clairement: lot, noir, piscine. A ce stade on peut s'interroger sur une possible correspondance entre fréquence d'un mot et appartenance à une catégorie de produit. Nous aurons l'occasion de creuser la question lorsqu'on affichera les fréquences de mots par catégories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0h0sUg7RlgX"
      },
      "source": [
        "Examinons maintenant la fréquence globale des mots, c'est à dire la fréquence des mots contenus dans la variable **text**, qui pour rappel est issue de la concaténation de **designation** et **description**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYGvnUOqNMWm"
      },
      "outputs": [],
      "source": [
        "# Génération du nuage de mots\n",
        "# Création de la chaine all_word_texte en combinant toutes les listes de mots\n",
        "all_word_texte = ' '.join([word for words_list in df['mots_text'] for word in words_list])\n",
        "\n",
        "wordcloud_texte = WordCloud(width = 800, height = 800, max_words = 1000, background_color = 'black',\n",
        "                      colormap = \"nipy_spectral\").generate(all_word_texte)\n",
        "\n",
        "plt.imshow(wordcloud_texte)\n",
        "plt.axis(\"off\")\n",
        "plt.title('Mots contenus dans le texte designation + description')\n",
        "plt.tight_layout(pad=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI5SNFv1RjU7"
      },
      "source": [
        "La prédominance du français est encore plus nette. Les rares mots anglais qu'on pouvait encore distinguer sont probablement encore plus en arrière-plan. On constate aussi que hormis *lot*, les mots les plus identifiables ont changé. C'est plutôt rassurant car ça signifie que le champ **description** apporte une information qui n'est pas redondante par rapport au champ **designation**.\n",
        "\n",
        "Plusieurs mots en évidence ont une consonance plutôt marketing que descriptive. Notamment *neuf*, *haute*, *qualité*. C'est attendu dans du texte destiné à inciter à la vente de produits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrK0jSJDNUqu"
      },
      "source": [
        "## Fréquence des mots dans le texte pour chaque catégorie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFNxybS9R4GN"
      },
      "source": [
        "Penchons nous maintenant sur la fréquence des mots au sein de chaque catégorie. On voudrait afficher pour chaque catégorie la fréquence des 10 mots les plus courants.\n",
        "\n",
        "Pour cela, on crée un DataFrame **df_plot** qui contient trois colonnes: **categorie**, **word** et **count**. Ce DataFrame aura donc 10 lignes par catégorie, chaque ligne correspondant à un des 10 mots les plus fréquents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N-67ponNVgC"
      },
      "outputs": [],
      "source": [
        "# Attention 2/3 min de calcul si effectué sur mots_texte\n",
        "# Calculer la fréquence des mots pour chaque catégorie\n",
        "word_counts_by_category = {}\n",
        "for category in df['categorie'].unique():\n",
        "    # Filtrer les lignes par catégorie\n",
        "    filtered_df = df[df['categorie'] == category]\n",
        "    # Combiner tous les mots de cette catégorie\n",
        "    all_words = sum(filtered_df['mots_text'], [])\n",
        "    # Compter les mots et stocker dans le dictionnaire\n",
        "    word_counts_by_category[category] = Counter(all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jzt4Os26Ncu9"
      },
      "outputs": [],
      "source": [
        "# Préparation des données pour Plotly\n",
        "data = []\n",
        "for category, counter in word_counts_by_category.items():\n",
        "    for word, count in counter.most_common(10):  # Top 10 mots pour chaque catégorie\n",
        "        data.append({'categorie': category, 'word': word, 'count': count})\n",
        "\n",
        "df_plot = pd.DataFrame(data)\n",
        "df_plot.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0VUMyE1SSDj"
      },
      "source": [
        "On peut maintenant utiliser **df_plot** pour afficher un ensemble de graphique en barre (un par catégorie) qui vont représenter les occurrences des dix mots les plus courants dans leur catégorie respective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSokOcBtNfw1"
      },
      "outputs": [],
      "source": [
        "# Obtenir les catégories uniques\n",
        "categories = df_plot['categorie'].unique()\n",
        "\n",
        "# Créer un ensemble de subplots (3 colonnes, 9 lignes)\n",
        "fig = make_subplots(rows=9, cols=3, subplot_titles=[f'Catégorie: {category}' for category in categories])\n",
        "\n",
        "# Fonction pour ajouter des barres horizontales pour chaque catégorie\n",
        "def add_bars(fig, df, category, row, col):\n",
        "    filtered_df = df[df['categorie'] == category].sort_values(by='count')\n",
        "    fig.add_trace(\n",
        "        go.Bar(y=filtered_df['word'], x=filtered_df['count'], name=str(category), orientation='h'),\n",
        "        row=row, col=col\n",
        "    )\n",
        "\n",
        "# Ajouter des barres pour chaque catégorie dans son subplot respectif\n",
        "row = 1\n",
        "col = 1\n",
        "for category in categories:\n",
        "    add_bars(fig, df_plot, category, row, col)\n",
        "    col += 1\n",
        "    if col > 3:\n",
        "        col = 1\n",
        "        row += 1\n",
        "\n",
        "# Mise à jour de la mise en page\n",
        "fig.update_layout(height=3000, width=1200, title_text=\"Fréquence des mots par catégorie de produit\", showlegend=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XRtK2KcSX7w"
      },
      "source": [
        "Bien que la plupart des catégories aient des mots qui reflètent leur thèmes, on constate fréquemment que des mots génériques tel que *peut*, *plus*, *être*, *cette* apparaissent dans le top 10. Ces mots ont probablement échappé à la liste des stop words censée les filtrer. Il n'apportent pas d'information sur la catégorie.\n",
        "\n",
        "D'autres termes typiques d'un vocabulaire produit sont notables tels que *dimension*, *taille*, *longueur*.  Eux non plus ne devraient pas aider à la classification.\n",
        "\n",
        "Enfin, on retrouve les mots classiques du marketing de vente qu'on avait déjà repéré: *haute*, *qualité*, *facile*.\n",
        "\n",
        "Si comme on le suppose, ces mots ne contribuent pas à la variance expliquée entre les classes de produits, il devraient être filtrés naturellement lors de la phase de sélection de features d'une réduction de dimension efficace.\n",
        "\n",
        "On note aussi certaines catégories particulières comme **livre neuf** dont les mots ne reflètent pas la nature. On dirait plutôt que les mots qui ressortent sont ceux des titres les plus vendus. Curieusement la catégorie **livre occasion** de partage pas cette caractéristique puisque son vocable correspond bien au monde de l'édition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Kh_zG9_j5E"
      },
      "source": [
        "Affichons maintenant les nuages de mots par catégorie. Cela nous fournira une vision plus exhaustive qu'un top 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bZqpqs1RIbC"
      },
      "outputs": [],
      "source": [
        "#TODO: ameliorer tqdm qui n'affiche pas le nombre totale d'iterations\n",
        "\n",
        "# Création de subplots pour les nuages de mots (3 colonnes x 9 lignes)\n",
        "fig, axes = plt.subplots(9, 3, figsize=(15, 45))\n",
        "\n",
        "# Assurer que les axes sont aplatis en un seul tableau si nécessaire\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (category, counts) in tqdm( enumerate(word_counts_by_category.items()) ):\n",
        "    # Génération du nuage de mots pour la catégorie\n",
        "    wordcloud = WordCloud(width=800, height=800, max_words=1000, background_color='black', colormap=\"nipy_spectral\").generate_from_frequencies(counts)\n",
        "\n",
        "    # Affichage du nuage de mots dans le subplot correspondant\n",
        "    axes[i].imshow(wordcloud, interpolation='bilinear')\n",
        "    axes[i].axis(\"off\")\n",
        "    axes[i].set_title(f'Catégorie: {category}')\n",
        "\n",
        "# Cacher les axes supplémentaires s'il y en a\n",
        "for j in range(i + 1, 27):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "# Ajustement de la mise en page\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E260xoslUVnL"
      },
      "source": [
        "Bien sûr les mots qu'on avait repéré dans le top 10 sont ici mis en évidence. Cette représentation permet toutefois de repérer certains mots plus en arrière plan qui n'apparaissaient pas sur le graphique précédent.\n",
        "\n",
        "Pour reprendre notre exemple de **livre neuf**, on observe la présence en retrait de quelques mots plus proches de l'édition tels que: *livre*, *ouvrage*, *tome*.\n",
        "\n",
        "Ça souligne une fois de plus l'importance qu'aura un bon process de sélection de features qui devra écarter les features les plus évidentes au profit de de feature plus explicatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jze6NJPETYjX"
      },
      "source": [
        "## test wordCloud avec masque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDTncKxwRK4m"
      },
      "outputs": [],
      "source": [
        "# Génération du nuage de mots\n",
        "image = plt.imread('Assets/Images/SuperNES.jpg')\n",
        "\n",
        "categorie_specifique = 'Console de jeu'\n",
        "\n",
        "if categorie_specifique in word_counts_by_category:\n",
        "    # Génération du nuage de mots pour la catégorie\n",
        "    wordcloud = WordCloud(width=800, height=800, max_words=1000,mask = image, background_color='black',\n",
        "                          colormap=\"nipy_spectral\").generate_from_frequencies(word_counts_by_category[categorie_specifique])\n",
        "\n",
        "    # Affichage du nuage de mots\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f'Catégorie \"{categorie_specifique}\"')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO4XMBm6ajII"
      },
      "outputs": [],
      "source": [
        "# Génération du nuage de mots\n",
        "image = plt.imread('Assets/Images/manette_xbox.jpg')\n",
        "\n",
        "categorie_specifique = 'Jeu occasion'\n",
        "\n",
        "if categorie_specifique in word_counts_by_category:\n",
        "    # Génération du nuage de mots pour la catégorie\n",
        "    wordcloud = WordCloud(width=800, height=800, max_words=1000,mask = image, background_color='#E0E0E0',\n",
        "                          colormap=\"nipy_spectral\").generate_from_frequencies(word_counts_by_category[categorie_specifique])\n",
        "\n",
        "    # Affichage du nuage de mots\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f'Catégorie \"{categorie_specifique}\"')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmPPEP-WWKxT"
      },
      "source": [
        "## Les images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2MsoF83vQey"
      },
      "source": [
        "TODO: parler du nb d'images dans les dossiers qui correspond bien au nb de produits dans X_train.csv\n",
        "\n",
        "TODO: parcourir les dossiers en python et vérifier que chaque image est bien présente ?\n",
        "\n",
        "TODO: parler des images miniatures dans un rectangle blanc. Montrer des exemples\n",
        "\n",
        "TODO: pourcentage de blanc dans les images ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyUnmo6OvGBx"
      },
      "source": [
        "Ajout d'un champs contenant le nom du fichier image.\n",
        "TODO: necessaire pour le traitement des images ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2ECOFI5WyEK"
      },
      "outputs": [],
      "source": [
        "# Conversion des colonnes 'imageid' et 'productid' en chaînes de caractères\n",
        "df['imageid'] = df['imageid'].astype(str)\n",
        "df['productid'] = df['productid'].astype(str)\n",
        "\n",
        "#Ajout colonne nom_fichier\n",
        "df['nom_fichier'] = \"image_\" + df['imageid'] + \"_product_\" + df['productid'] + \".jpg\"\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiqVd2h8LP1W"
      },
      "source": [
        "# TODO: corriger l'orthographe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n43e89YxMSzr"
      },
      "source": [
        "# TODO: sortir des chiffres (stats) pour compléter l'interpretation des graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5MMuXXzIK0X"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRg2_PeEQMV_"
      },
      "source": [
        "# TODO: choisir une langue unique pour le code (anglais?)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IOdUnOfdun02",
        "n43e89YxMSzr"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
